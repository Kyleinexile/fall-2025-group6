import streamlit as st
import sys
import pathlib

# Setup path
REPO_ROOT = pathlib.Path(__file__).resolve().parents[3]
SRC = REPO_ROOT / "src"
if str(SRC) not in sys.path:
    sys.path.insert(0, str(SRC))

st.set_page_config(page_title="Project Overview", page_icon="ğŸ“Š", layout="wide")

# Header
st.title("ğŸ¯ USAF KSA Extraction Pipeline")
st.markdown("### Capstone Project: Automated Knowledge, Skills, and Abilities Extraction")
st.markdown("**Presented by:** Kyle | **Date:** October 22, 2025")
st.divider()

# Project Overview Section
col1, col2 = st.columns([2, 1])

with col1:
    st.markdown("## ğŸ“‹ Project Overview")
    st.markdown("""
    This capstone project develops an **automated pipeline** for extracting Knowledge, Skills, and Abilities (KSAs) 
    from U.S. Air Force Specialty Code (AFSC) descriptions. The system combines LAiSER (Leveraging AI for Skills Extraction & Research) 
    with modern Large Language Models to create a comprehensive KSA database stored in a Neo4j graph database.
    
    **Problem Statement:**
    - Manual KSA extraction from AFSC documentation is time-consuming and inconsistent
    - No standardized taxonomy mapping for military skills
    - Difficult to compare skills across different career fields
    
    **Solution:**
    - Automated extraction using LAiSER + LLM enhancement
    - ESCO taxonomy integration for skill standardization
    - Interactive graph database for analysis and comparison
    """)

with col2:
    st.markdown("## ğŸ¯ Key Objectives")
    st.success("âœ… Integrate LAiSER framework")
    st.success("âœ… Extract all 3 KSA types")
    st.success("âœ… Minimum 3 KSAs per AFSC")
    st.success("âœ… Graph database storage")
    st.success("âœ… Professional web interface")
    st.info("ğŸ”„ Process 12 AFSCs")

st.divider()

# KSA Definitions Section
st.markdown("## ğŸ“š What are KSAs?")

col_k, col_s, col_a = st.columns(3)

with col_k:
    st.markdown("### ğŸ“– Knowledge")
    st.markdown("""
    **Definition:** The body of information that is necessary to perform a task.
    
    **Examples:**
    - Knowledge of intelligence cycle fundamentals
    - Knowledge of geospatial analysis techniques
    - Knowledge of threat assessment methodologies
    
    **Characteristics:**
    - Theoretical understanding
    - Factual information
    - Domain expertise
    """)

with col_s:
    st.markdown("### ğŸ› ï¸ Skills")
    st.markdown("""
    **Definition:** Observable, measurable proficiencies required to perform job activities.
    
    **Examples:**
    - Perform intelligence data analysis
    - Conduct collection management
    - Prepare intelligence reports
    
    **Characteristics:**
    - Action-oriented
    - Demonstrable competencies
    - Technical capabilities
    """)

with col_a:
    st.markdown("### ğŸ’ª Abilities")
    st.markdown("""
    **Definition:** Enduring attributes that enable task performance under varying conditions.
    
    **Examples:**
    - Ability to synthesize multi-source data
    - Ability to work under time constraints
    - Ability to communicate complex information
    
    **Characteristics:**
    - Cognitive/physical capacities
    - Adaptable traits
    - Performance enablers
    """)

st.divider()

# Pipeline Architecture Section
st.markdown("## ğŸ”„ Extraction Pipeline Architecture")

st.markdown("""
Our pipeline combines multiple technologies to achieve comprehensive KSA extraction:
""")

# Visual pipeline flow
st.code("""
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. INPUT: AFSC Description (PDF/Text)                          â”‚
â”‚    â€¢ Air Force Specialty Code documentation                     â”‚
â”‚    â€¢ Duties, responsibilities, and requirements                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. PREPROCESSING: Text Cleaning                                â”‚
â”‚    â€¢ Remove formatting artifacts                                â”‚
â”‚    â€¢ Normalize text structure                                   â”‚
â”‚    â€¢ Extract relevant sections                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. LAiSER: Skill Extraction                                     â”‚
â”‚    â€¢ Pattern-based phrase detection                             â”‚
â”‚    â€¢ ESCO taxonomy matching                                     â”‚
â”‚    â€¢ Confidence scoring                                         â”‚
â”‚    OUTPUT: 3-6 Skills with ESCO IDs                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. LLM ENHANCEMENT: Knowledge + Ability Generation             â”‚
â”‚    â€¢ Google Gemini 1.5 Flash (primary)                         â”‚
â”‚    â€¢ Anthropic Claude (fallback)                               â”‚
â”‚    â€¢ Context-aware K/A statements                              â”‚
â”‚    OUTPUT: 3-6 Knowledge + Ability items                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. CONSOLIDATION: Deduplication & Validation                   â”‚
â”‚    â€¢ Remove duplicate items                                     â”‚
â”‚    â€¢ Validate K/S/A balance                                     â”‚
â”‚    â€¢ Quality filtering                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 6. STORAGE: Neo4j Graph Database                               â”‚
â”‚    â€¢ AFSC nodes with relationships                              â”‚
â”‚    â€¢ KSA nodes with properties                                  â”‚
â”‚    â€¢ HAS_ITEM relationships                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 7. DISPLAY: Interactive Streamlit Interface                    â”‚
â”‚    â€¢ Search and filter capabilities                             â”‚
â”‚    â€¢ Cross-AFSC comparison                                      â”‚
â”‚    â€¢ Export functionality                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
""", language="text")

st.divider()

# Technology Stack Section
st.markdown("## ğŸ”§ Technology Stack")

col_tech1, col_tech2, col_tech3 = st.columns(3)

with col_tech1:
    st.markdown("### ğŸ¤– AI/ML Components")
    st.markdown("""
    - **LAiSER**: Skill extraction & ESCO mapping
    - **Google Gemini 1.5 Flash**: Free LLM (15 RPM)
    - **Anthropic Claude Sonnet 4.5**: Fallback LLM
    - **Pattern Matching**: Fallback extraction
    """)

with col_tech2:
    st.markdown("### ğŸ’¾ Data & Storage")
    st.markdown("""
    - **Neo4j Aura**: Graph database (cloud)
    - **ESCO Taxonomy**: EU skills classification
    - **Python 3.11**: Core language
    - **Pandas**: Data processing
    """)

with col_tech3:
    st.markdown("### ğŸŒ Interface & Deployment")
    st.markdown("""
    - **Streamlit**: Web application framework
    - **GitHub**: Version control & CI/CD
    - **Streamlit Cloud**: Production hosting
    - **Codespaces**: Development environment
    """)

st.divider()

# Current Progress Section
st.markdown("## ğŸ“Š Current Project Status")

# Metrics
col_m1, col_m2, col_m3, col_m4, col_m5 = st.columns(5)

with col_m1:
    st.metric("AFSCs Processed", "1/12", delta="8%")
with col_m2:
    st.metric("Total KSAs", "7+", delta="per AFSC")
with col_m3:
    st.metric("Avg Confidence", "0.63", delta="Good")
with col_m4:
    st.metric("Processing Time", "~8 sec", delta="per AFSC")
with col_m5:
    st.metric("System Status", "âœ… Online")

st.markdown("---")

# Progress breakdown
col_p1, col_p2 = st.columns(2)

with col_p1:
    st.markdown("### âœ… Completed Components")
    st.markdown("""
    - âœ… LAiSER integration (pattern-based fallback working)
    - âœ… LLM enhancement with Gemini + Anthropic
    - âœ… Heuristic fallback (always functional)
    - âœ… Neo4j database schema and connections
    - âœ… Streamlit 5-page web interface
    - âœ… Admin Ingest pipeline (LAiSER â†’ LLM â†’ DB)
    - âœ… Explore KSAs page with filtering
    - âœ… View Docs page for source material
    - âœ… End-to-end pipeline testing
    """)

with col_p2:
    st.markdown("### ğŸ”„ In Progress")
    st.markdown("""
    - ğŸ”„ Processing remaining 11 AFSCs (target: 3-5/day)
    - ğŸ”„ Quality assurance review
    - ğŸ”„ Statistical analysis and reporting
    - ğŸ”„ Cross-AFSC comparison analysis
    
    ### ğŸ¯ Next Steps
    - Complete 12 AFSC processing
    - Generate comprehensive statistics
    - Finalize presentation materials
    - Prepare deployment documentation
    """)

st.divider()

# Results & Performance Section
st.markdown("## ğŸ“ˆ Pipeline Performance")

col_r1, col_r2 = st.columns(2)

with col_r1:
    st.markdown("### Extraction Results (AFSC 14N)")
    results_data = {
        "Component": ["LAiSER Skills", "LLM Knowledge", "LLM Abilities", "Total"],
        "Count": [3, 3, 1, 7],
        "Avg Confidence": [0.55, 0.70, 0.70, 0.63],
        "Source": ["fallback-pattern", "llm-gemini", "llm-gemini", "mixed"]
    }
    st.dataframe(results_data, use_container_width=True, hide_index=True)
    
    st.markdown("**Quality Metrics:**")
    st.markdown("- âœ… All 3 KSA types present")
    st.markdown("- âœ… Exceeds 3 KSA minimum (7 total)")
    st.markdown("- âœ… Confidence scores 0.50-0.70 (acceptable)")

with col_r2:
    st.markdown("### System Capabilities")
    st.markdown("""
    **Strengths:**
    - âœ… Consistent K/S/A extraction across AFSCs
    - âœ… Automatic fallback prevents failures
    - âœ… Free API usage (no ongoing costs)
    - âœ… Real-time processing (~8 seconds)
    - âœ… Scalable to hundreds of AFSCs
    
    **Future Improvements:**
    - ğŸ”® Enable full LAiSER engine with models
    - ğŸ”® Implement batch processing
    - ğŸ”® Add custom ESCO taxonomy training
    - ğŸ”® Automated quality scoring
    """)

st.divider()

# Demo Workflow Section
st.markdown("## ğŸ¬ Live Demo Workflow")

st.markdown("""
### What We'll Demonstrate:

1. **Admin Ingest Page** - Load AFSC, watch pipeline process, view results
2. **Explore KSAs Page** - Search, filter, compare, and export data
3. **View Docs Page** - Access source documentation
4. **Technical Architecture** - Review code and database structure
""")

st.divider()

st.markdown("---")
st.caption("ğŸš€ USAF KSA Extraction Pipeline | Capstone Project 2025")
